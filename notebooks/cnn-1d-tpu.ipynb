{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "cnn-1d.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauricio-ms/motor-imagery-convolutional-recurrent-neural-network/blob/master/notebooks/cnn-1d-tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik5Iayk0b9VF",
        "colab_type": "text"
      },
      "source": [
        "Verify if TPU is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5WSlVTEsUgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d829dc7f-ee28-465c-da7e-3a8a2d48a59c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1acvmVTscFNB",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_U7VQvebX5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "940ef744-a4a4-43ac-ee5c-e3371521a813"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnJhUd3kIwB9",
        "colab_type": "text"
      },
      "source": [
        "Unzip dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQDEMdNAlgmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97b2e0d7-7141-4a2c-e7d9-275f8f993f68"
      },
      "source": [
        "!tar -xf \"drive/My Drive/motor-imagery-convolutional-recurrent-neural-network/raw-csv-files.tar.xz\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE_6jekhJsut",
        "colab_type": "text"
      },
      "source": [
        "Install needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0G2d-3FJvOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b651bac-f3f0-449a-c7ba-dd1087487b28"
      },
      "source": [
        "!pip install colorlog"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (4.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MGP1QOJJg1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import colorlog\n",
        "\n",
        "\n",
        "def get_logger(name=\"__main__\", debug=False):\n",
        "    log_format = (\n",
        "        \"[%(levelname)s] \"\n",
        "        \"%(asctime)s - \"\n",
        "        \"%(name)s: \"\n",
        "        \"%(funcName)s - \"\n",
        "        \"%(message)s\"\n",
        "    )\n",
        "    bold_seq = \"\\033[1m\"\n",
        "    colorlog_format = (\n",
        "        f\"{bold_seq} \"\n",
        "        \"%(log_color)s \"\n",
        "        f\"{log_format}\"\n",
        "    )\n",
        "    colorlog.basicConfig(format=colorlog_format)\n",
        "\n",
        "    logger = logging.getLogger(name)\n",
        "    if debug:\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "    else:\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Output full log\n",
        "    fh = logging.FileHandler(\"app.log\")\n",
        "    fh.setLevel(logging.DEBUG)\n",
        "    formatter = logging.Formatter(log_format)\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "    return logger"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcMErN9zJ9b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "LOGGER = get_logger(\"physionet.py\")\n",
        "N_CHANNELS = 64\n",
        "PREPROCESSED_CSV_FILES_DIR = \"raw-csv-files\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi6uU8aLJE5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(train_size=0.75, validation_size=None, n_subjects=None, **kwargs):\n",
        "    LOGGER.info(\"Loading Physionet dataset ...\")\n",
        "    subjects = np.array(sorted(os.listdir(PREPROCESSED_CSV_FILES_DIR)))\n",
        "    if n_subjects is not None:\n",
        "        subjects = subjects[:n_subjects]\n",
        "    train_subjects, test_subjects = _train_test_split_subjects(subjects, train_size)\n",
        "    if validation_size is not None:\n",
        "        train_subjects, validation_subjects = _train_test_split_subjects(train_subjects, 1-validation_size)\n",
        "        LOGGER.info(f\"(Train, Validation, Test) Subjects = \"\n",
        "                    f\"({len(train_subjects)}, {len(validation_subjects)}, {len(test_subjects)})\")\n",
        "        return _load_set(train_subjects, **kwargs), \\\n",
        "            _load_set(validation_subjects, **kwargs), \\\n",
        "            _load_set(test_subjects, **kwargs)\n",
        "\n",
        "    LOGGER.info(f\"(Train, Validation) Subjects = ({len(train_subjects)}, {len(test_subjects)})\")\n",
        "    return _load_set(train_subjects, **kwargs), _load_set(test_subjects, **kwargs)\n",
        "\n",
        "\n",
        "def _train_test_split_subjects(subjects, train_size):\n",
        "    train_subjects_mask = np.random.rand(len(subjects)) < train_size\n",
        "    return subjects[train_subjects_mask], subjects[~train_subjects_mask]\n",
        "\n",
        "\n",
        "def _load_set(subjects, n_readers=5, n_parse_threads=5, batch_size=100,\n",
        "              convert_to_2d=False, expand_dim=False):\n",
        "    path_files = [os.path.join(PREPROCESSED_CSV_FILES_DIR, subject, file_name)\n",
        "                  for subject in subjects\n",
        "                  for file_name in sorted(os.listdir(os.path.join(PREPROCESSED_CSV_FILES_DIR, subject)))]\n",
        "    dataset = tf.data.Dataset.list_files(path_files)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers)\n",
        "    dataset = dataset.map(lambda r: _preprocess(r, convert_to_2d=convert_to_2d,\n",
        "                                                expand_dim=expand_dim),\n",
        "                          num_parallel_calls=n_parse_threads)\n",
        "    return dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "\n",
        "def _preprocess(eeg_record, convert_to_2d=False, expand_dim=False):\n",
        "    # Create the definitions for the columns (channels + label)\n",
        "    # The empty array tells TensorFlow to raise exception to missing values\n",
        "    defs = [tf.constant([], dtype=tf.float32)] * (N_CHANNELS + 1)\n",
        "    fields = tf.io.decode_csv(eeg_record, record_defaults=defs)\n",
        "    x = _get_features(fields, convert_to_2d=convert_to_2d)\n",
        "    if expand_dim:\n",
        "        x = x[..., np.newaxis]\n",
        "    y = tf.cast(tf.stack(fields[-1:]), tf.int32)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def _get_features(fields, convert_to_2d=False):\n",
        "    return tf.stack(fields[:-1])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijlydjzMuvIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8e068a90-fee1-4a7a-e344-88b6b1a0f60e"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "batch_size=500\n",
        "\n",
        "train_set, validation_set, test_set = load_data(expand_dim=True, \n",
        "                                                validation_size=0.20,\n",
        "                                                batch_size=batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:15:50,517 - physionet.py: load_data - Loading Physionet dataset ...\u001b[0m\n",
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:15:50,519 - physionet.py: load_data - (Train, Validation, Test) Subjects = (66, 16, 26)\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3yiuRAHs_dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "d4b5cf07-1301-4c2e-c1ca-5fcd1a3a276c"
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Conv1D(32, 3, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          padding=\"SAME\",\n",
        "                          input_shape=[64, 1]),\n",
        "      keras.layers.Conv1D(64, 3, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          padding=\"SAME\"),\n",
        "      keras.layers.Conv1D(128, 3, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          padding=\"SAME\"),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(1024, activation=\"relu\",\n",
        "                        kernel_initializer=\"he_normal\"),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(5, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(lr=1e-4)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.26.123.218:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.26.123.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:15:55,868 - tensorflow: initialize_tpu_system - Initializing the TPU system: grpc://10.26.123.218:8470\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,964 - tensorflow: initialize_tpu_system - Clearing out eager caches\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,970 - tensorflow: initialize_tpu_system - Finished initializing TPU system.\u001b[0m\n",
            "\u001b[1m \u001b[33m [WARNING] 2020-08-13 23:16:11,974 - absl: __init__ - `tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,979 - tensorflow: _query_tpu_system_metadata - Found TPU system:\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,983 - tensorflow: _query_tpu_system_metadata - *** Num TPU Cores: 8\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,985 - tensorflow: _query_tpu_system_metadata - *** Num TPU Workers: 1\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,987 - tensorflow: _query_tpu_system_metadata - *** Num TPU Cores Per Worker: 8\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,991 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,993 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,995 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:11,997 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,001 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,003 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,004 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,006 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,011 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,015 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,017 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,020 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:12,021 - tensorflow: _query_tpu_system_metadata - *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etNllQYoaqEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "68431e2b-c08d-46d9-8e4a-e5cf6bf9d3f7"
      },
      "source": [
        "LOGGER.info(\"Starting training CNN 1D model ...\")\n",
        "model.fit(train_set, epochs=2,\n",
        "          validation_data=validation_set)\n",
        "LOGGER.info(\"Training CNN 1D model end!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-13 23:16:13,493 - physionet.py: <module> - Starting training CNN 1D model ...\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b368efaaf172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training CNN 1D model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(train_set, epochs=2, \n\u001b[0;32m----> 3\u001b[0;31m           validation_data=validation_set)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training CNN 1D model end!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, steps, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[0;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[1;32m    742\u001b[0m                          \"specify the number of steps to run.\")\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m       \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFINITE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Unable to parse tensor proto"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbdSNPtjdslr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "965fc4c3-dd43-4288-ff4c-b7d06a125201"
      },
      "source": [
        "train_set"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 5, 1), (None, 1)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}