{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "cnn-1d.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauricio-ms/motor-imagery-convolutional-recurrent-neural-network/blob/master/notebooks/cnn-1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik5Iayk0b9VF",
        "colab_type": "text"
      },
      "source": [
        "Verify if GPU is enabled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAciPmXZdfjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f57666c-cb6b-4552-e047-8762278d2be9"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != \"/device:GPU:0\":\n",
        "  raise SystemError(\"GPU device not found\")\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1acvmVTscFNB",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_U7VQvebX5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7d00d2cc-1d3f-45ae-ed25-57522d84be8f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnJhUd3kIwB9",
        "colab_type": "text"
      },
      "source": [
        "Unzip dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQDEMdNAlgmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf \"drive/My Drive/motor-imagery-convolutional-recurrent-neural-network/preprocessed-csv-files.tar.xz\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE_6jekhJsut",
        "colab_type": "text"
      },
      "source": [
        "Install needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0G2d-3FJvOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "909385ce-543a-494a-ee4a-16f918d41fc4"
      },
      "source": [
        "!pip install colorlog"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Installing collected packages: colorlog\n",
            "Successfully installed colorlog-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MGP1QOJJg1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import colorlog\n",
        "\n",
        "\n",
        "def get_logger(name=\"__main__\", debug=False):\n",
        "    log_format = (\n",
        "        \"[%(levelname)s] \"\n",
        "        \"%(asctime)s - \"\n",
        "        \"%(name)s: \"\n",
        "        \"%(funcName)s - \"\n",
        "        \"%(message)s\"\n",
        "    )\n",
        "    bold_seq = \"\\033[1m\"\n",
        "    colorlog_format = (\n",
        "        f\"{bold_seq} \"\n",
        "        \"%(log_color)s \"\n",
        "        f\"{log_format}\"\n",
        "    )\n",
        "    colorlog.basicConfig(format=colorlog_format)\n",
        "\n",
        "    logger = logging.getLogger(name)\n",
        "    if debug:\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "    else:\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Output full log\n",
        "    fh = logging.FileHandler(\"app.log\")\n",
        "    fh.setLevel(logging.DEBUG)\n",
        "    formatter = logging.Formatter(log_format)\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "    return logger"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcMErN9zJ9b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "LOGGER = get_logger(\"physionet.py\")\n",
        "N_CHANNELS = 64\n",
        "PREPROCESSED_CSV_FILES_DIR = \"preprocessed-csv-files\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi6uU8aLJE5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(train_size=0.75, validation_size=None, n_subjects=None, **kwargs):\n",
        "    LOGGER.info(\"Loading Physionet dataset ...\")\n",
        "    subjects = np.array(sorted(os.listdir(PREPROCESSED_CSV_FILES_DIR)))\n",
        "    if n_subjects is not None:\n",
        "        subjects = subjects[:n_subjects]\n",
        "    train_subjects, test_subjects = _train_test_split_subjects(subjects, train_size)\n",
        "    if validation_size is not None:\n",
        "        train_subjects, validation_subjects = _train_test_split_subjects(train_subjects, 1-validation_size)\n",
        "        LOGGER.info(f\"(Train, Validation, Test) Subjects = \"\n",
        "                    f\"({len(train_subjects)}, {len(validation_subjects)}, {len(test_subjects)})\")\n",
        "        return _load_set(train_subjects, **kwargs), \\\n",
        "            _load_set(validation_subjects, **kwargs), \\\n",
        "            _load_set(test_subjects, **kwargs)\n",
        "\n",
        "    LOGGER.info(f\"(Train, Validation) Subjects = ({len(train_subjects)}, {len(test_subjects)})\")\n",
        "    return _load_set(train_subjects, **kwargs), _load_set(test_subjects, **kwargs)\n",
        "\n",
        "\n",
        "def _train_test_split_subjects(subjects, train_size):\n",
        "    train_subjects_mask = np.random.rand(len(subjects)) < train_size\n",
        "    return subjects[train_subjects_mask], subjects[~train_subjects_mask]\n",
        "\n",
        "\n",
        "def _load_set(subjects, n_readers=5, n_parse_threads=5, batch_size=100,\n",
        "              convert_to_2d=False, expand_dim=False):\n",
        "    path_files = [os.path.join(PREPROCESSED_CSV_FILES_DIR, subject, file_name)\n",
        "                  for subject in subjects\n",
        "                  for file_name in sorted(os.listdir(os.path.join(PREPROCESSED_CSV_FILES_DIR, subject)))]\n",
        "    dataset = tf.data.Dataset.list_files(path_files)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers)\n",
        "    dataset = dataset.map(lambda r: _preprocess(r, convert_to_2d=convert_to_2d,\n",
        "                                                expand_dim=expand_dim),\n",
        "                          num_parallel_calls=n_parse_threads)\n",
        "    return dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "\n",
        "def _preprocess(eeg_record, convert_to_2d=False, expand_dim=False):\n",
        "    # Create the definitions for the columns (channels + label)\n",
        "    # The empty array tells TensorFlow to raise exception to missing values\n",
        "    defs = [tf.constant([], dtype=tf.float32)] * (N_CHANNELS + 1)\n",
        "    fields = tf.io.decode_csv(eeg_record, record_defaults=defs)\n",
        "    x = _get_features(fields, convert_to_2d=convert_to_2d)\n",
        "    if expand_dim:\n",
        "        x = x[..., np.newaxis]\n",
        "    y = tf.cast(tf.stack(fields[-1:]), tf.int32)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def _get_features(fields, convert_to_2d=False):\n",
        "    return tf.stack(fields[:-1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmenY4YTJTg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0a749d4a-c140-48c3-f349-94b55a4566cb"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  train_set, validation_set, test_set = load_data(expand_dim=True, \n",
        "                                                  validation_size=0.10,\n",
        "                                                  n_readers=50,\n",
        "                                                  n_parse_threads=50)\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Conv1D(32, 3, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          padding=\"SAME\",\n",
        "                          input_shape=[64, 1]),\n",
        "      keras.layers.Conv1D(64, 3, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          padding=\"SAME\"),\n",
        "      keras.layers.Conv1D(128, 3, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          padding=\"SAME\"),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(1024, activation=\"relu\",\n",
        "                        kernel_initializer=\"he_normal\"),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(5, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(lr=1e-4)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-14 01:54:40,107 - physionet.py: load_data - Loading Physionet dataset ...\u001b[0m\n",
            "\u001b[1m \u001b[32m [INFO] 2020-08-14 01:54:40,113 - physionet.py: load_data - (Train, Validation, Test) Subjects = (70, 11, 27)\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etNllQYoaqEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "6f277f54-f358-4a85-825e-7bb53b19e3fd"
      },
      "source": [
        "LOGGER.info(\"Starting training CNN 1D model ...\")\n",
        "model.fit(train_set, epochs=300, validation_data=validation_set, verbose=2)\n",
        "LOGGER.info(\"Training CNN 1D model end!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \u001b[32m [INFO] 2020-08-14 01:54:45,975 - physionet.py: <module> - Starting training CNN 1D model ...\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "177689/177689 - 3152s - loss: 0.8574 - accuracy: 0.6581 - val_loss: 1.5192 - val_accuracy: 0.5354\n",
            "Epoch 2/300\n",
            "177689/177689 - 3054s - loss: 0.9452 - accuracy: 0.6229 - val_loss: 1.7619 - val_accuracy: 0.5083\n",
            "Epoch 3/300\n",
            "177689/177689 - 3049s - loss: 1.0351 - accuracy: 0.5942 - val_loss: 1.5974 - val_accuracy: 0.4995\n",
            "Epoch 4/300\n",
            "177689/177689 - 3195s - loss: 1.0572 - accuracy: 0.5847 - val_loss: 1.5349 - val_accuracy: 0.4990\n",
            "Epoch 5/300\n",
            "177689/177689 - 3250s - loss: 1.0737 - accuracy: 0.5792 - val_loss: 1.5011 - val_accuracy: 0.5327\n",
            "Epoch 6/300\n",
            "177689/177689 - 3347s - loss: 1.0890 - accuracy: 0.5738 - val_loss: 1.4373 - val_accuracy: 0.5389\n",
            "Epoch 7/300\n",
            "177689/177689 - 3428s - loss: 1.1007 - accuracy: 0.5711 - val_loss: 1.3945 - val_accuracy: 0.5383\n",
            "Epoch 8/300\n",
            "177689/177689 - 3189s - loss: 1.1052 - accuracy: 0.5696 - val_loss: 1.4562 - val_accuracy: 0.5276\n",
            "Epoch 9/300\n",
            "177689/177689 - 2994s - loss: 1.1322 - accuracy: 0.5626 - val_loss: 1.4474 - val_accuracy: 0.5359\n",
            "Epoch 10/300\n",
            "177689/177689 - 3047s - loss: 1.1169 - accuracy: 0.5658 - val_loss: 1.8266 - val_accuracy: 0.5311\n",
            "Epoch 11/300\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}